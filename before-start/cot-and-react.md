---
description: Chain of Thought and ReAct
layout:
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# CoT and ReAct

åœ¨Openaiæœ€ä½³å®è·µç³»åˆ—çš„å®˜æ–¹æ–‡æ¡£ä¸­æåˆ°ï¼Œç»™äºˆGPTæ—¶é—´å»æ€è€ƒã€‚é‚£ä¹ˆè¿™æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿ

å®˜æ–¹ä¸¾äº†ä¸€ä¸ªä¾‹å­ï¼Œè¯¢é—®å­¦ç”Ÿçš„å›ç­”æ˜¯å¦æ­£ç¡®ã€‚åœ¨å¸¸è§„çš„é—®ç­”åœºæ™¯ä¸‹ï¼ŒGPTé”™è¯¯åœ°è®¤ä¸ºå­¦ç”Ÿçš„å›ç­”æ˜¯æ­£ç¡®ã€‚

ç¬¬äºŒæ¬¡ä¿®æ”¹promptï¼Œè®©GPTå…ˆå°è¯•æ ¹æ®æé—®è‡ªå·±è®¡ç®—ä¸€éï¼Œå†é€šè¿‡è®¡ç®—çš„ç»“æœå’Œå­¦ç”Ÿçš„ç­”æ¡ˆåšå¯¹æ¯”ï¼Œè¿™æ ·å°±å¯ä»¥å¾—å‡ºæ­£ç¡®çš„åˆ¤æ–­ã€‚

<figure><img src="../.gitbook/assets/image (15).png" alt=""><figcaption></figcaption></figure>

è¿™å…¶å®å°±æ˜¯è®©GPTæ€è€ƒçš„ä¸€ç§æ–¹å¼ã€‚é‚£ä¹ˆæˆ‘ä»¬æ¥æ›´è¯¦ç»†åœ°è¯´ä¸€ä¸‹ä»€ä¹ˆæ˜¯Chain of Thought å’Œ ReActæ€ç»´ï¼Œè¿›ä¸€æ­¥äº†è§£AIåŠå¤§æ¨¡å‹çš„å¤„ç†æ–¹å¼ï¼Œæ–¹ä¾¿åœ¨å¼€å‘è¿‡ç¨‹ä¸­è¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚



### Chain of Thought

ChatGPTçš„ä½œè€…ä¹‹ä¸€ Jasonå‘è¡¨çš„ä¸€ç¯‡è®ºæ–‡ä¸­è®²è¿°äº†ä»€ä¹ˆæ˜¯CoTï¼š

ä¸€èˆ¬çš„æ¨¡å‹é—®ç­”ï¼Œéƒ½å€¾å‘äºæˆ–è€…è¯´åªèƒ½ä¸€æ­¥ä½œç­”ï¼Œä¹Ÿå°±æ˜¯ç¼ºå°‘æ¨ç†çš„è¿‡ç¨‹ï¼Œè¿™æ ·çš„ç»“æœæ˜¯ï¼Œç­”æ¡ˆé”™è¯¯ç™¾å‡ºã€‚åªè¦é—®é¢˜å¤šä¸¤ä¸ªå¼¯æ¨¡å‹å°±æ²¡æ³•ç©è½¬ã€‚

CoTçš„æ¨¡å¼æ˜¯ï¼ŒæŠŠäººç±»æ€è€ƒçš„è¿‡ç¨‹ï¼Œç”¨è‡ªç„¶è¯­è¨€çš„å½¢å¼ï¼Œæ˜¾æ€§åœ°æ”¾åœ¨prompt messageä¸­ã€‚

<figure><img src="../.gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

è¿™æ ·æ™®é€šçš„ _input prompt, output message_ å°±è¢«è½¬åŒ–æˆ \
_input prmopt(include CoT) and output(include CoT) message_

å½“Chain of Thoughtæ”¾åœ¨promptä¹‹åï¼Œæ¨¡å‹åœ¨ç»™å‡ºç­”æ¡ˆå‰ä¹Ÿä¼šå¼ºåˆ¶è¾“å‡ºCoTï¼Œä»æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„è§’åº¦æ¥è®²ï¼Œç­”æ¡ˆåœ¨chain of thoughtåï¼Œå…¶å‡†ç¡®çš„å¯èƒ½æ€§æ›´å¤§ã€‚è¿™ä¹Ÿä½è¯äº†ä¸€ç‚¹ï¼Œæ¨¡å‹å…¶å®æœ¬èº«æ²¡æœ‰æ€è€ƒï¼Œåªåœ¨ä¹è¾“å‡ºã€‚

å½“ç„¶Jasonä¹Ÿæåˆ°ï¼ŒCoTå¼promptä¸ä¼šå¯¹å°æ¨¡å‹çš„æ€§èƒ½äº§ç”Ÿç§¯æå½±å“ï¼Œåªæœ‰åœ¨ä½¿ç”¨å¤§çº¦1000äº¿å‚æ•°çš„æ¨¡å‹æ—¶æ‰ä¼šäº§ç”Ÿæ€§èƒ½æå‡ã€‚å°è§„æ¨¡çš„æ¨¡å‹äº§ç”Ÿçš„æ€ç»´é“¾æµç•…ä½†ä¸åˆé€»è¾‘ï¼Œå› æ­¤æ€§èƒ½ä½äºæ ‡å‡†æç¤ºã€‚

åœ¨ChatGPTä¹‹å‰ï¼Œä¹Ÿæœ‰å¾ˆå¤šå…¶ä»–å¤§è¯­è¨€æ¨¡å‹ï¼Œä½†GPTæœ‰å¦‚æ­¤çªå‡ºçš„è¡¨ç°ï¼ŒåŸºäºJasonå’ŒChatGPTçš„è”ç³»ï¼Œé’ˆå¯¹ç”¨æˆ·çš„è¾“å…¥å’Œä»»åŠ¡ï¼ŒçŒœæµ‹GPTåŒ…å«äº†ä¸€äº›éšå¼çš„CoTã€‚

æ™®é€šç”¨æˆ·åœ¨æ²¡æœ‰CoTçš„æƒ³æ³•ä¹‹å‰ï¼Œåªèƒ½ä¾é å¤§æ¨¡å‹æœ¬èº«çš„æ€ç»´æ¥å¤„ç†ï¼Œè¿™ä¸ªçº¯ç²¹å€šèµ–å¤§æ¨¡å‹è®­ç»ƒçš„ç»“æœ(Few-Shot-CoT)ã€‚

#### Zero-shot CoT

åœ¨å¦ä¸€ç¯‡ LLM are Zero-Shot Reasoners è®ºæ–‡ä¸­ï¼Œä½œè€…å°å²›æ­¦ç®€åŒ–äº†CoTçš„è¿‡ç¨‹ï¼Œä¹Ÿå°±æ˜¯æ— éœ€æ¨¡å‹è®­ç»ƒï¼Œé€šè¿‡ç‰¹å®šçš„prmoptè®©æ¨¡å‹è‡ªåŠ¨ç”ŸæˆCoTçš„æ–¹å¼æ¥åŠ å¼ºAIçš„å›ç­”(zero-shot CoT)

<figure><img src="../.gitbook/assets/image (5).png" alt=""><figcaption><p>compare with Few-shot, Zero-shot, Few-shot-CoT and Zero-shot-CoT</p></figcaption></figure>

ä»–é€šè¿‡åœ¨ä¸­é—´è¿‡ç¨‹ä¸­åŠ äº†å¾ˆç®€å•çš„ä¸€å¥è¯ï¼š_**"Let's think step by step",**_  å°±å¯ä»¥è®©æ²¡æœ‰CoTæ€ç»´çš„æ¨¡å‹è¿›åŒ–å›ç­”ã€‚

> _We propose Zero-shot-CoT, a zero-shot template-based prompting for chain of thought reasoning. It differs from the original chain of thought prompting \[Wei et al., 2022] as it does not require step-by-step few-shot examples, and it differs from most of the prior template prompting \[Liu et al., 2021b] as it is inherently task-agnostic and elicits multi-hop reasoning across a wide range of tasks with a single template. The core idea of our method is simple, as described in Figure 1: add **Letâ€™s think step by step**, or a a similar text (see Table 4), to extract step-by-step reasoning._

é‚£ä¹ˆè¿™æ˜¯æ€ä¹ˆå®ç°çš„å‘¢ï¼Ÿ  Zero-shot CoTçš„æ“ä½œè¿™æ ·çš„ï¼š

<figure><img src="../.gitbook/assets/image (4).png" alt=""><figcaption><p>Zero-shot CoT</p></figcaption></figure>

å®ƒé€šè¿‡ä¸¤æ¬¡promptæ¥å®ç°ã€‚ç¬¬ä¸€ä¸ªé€šè¿‡ _**â€œLetâ€™s think step by stepâ€**_, è®©æ¨¡å‹è¿›è¡Œæ€è€ƒï¼›ç¬¬äºŒæ¬¡å°†æ€è€ƒçš„è¿‡ç¨‹è”åˆç¬¬ä¸€æ¬¡çš„é—®é¢˜ï¼ŒåŠ ä¸Šprmopt: "_**The answer is**_" ä¸€èµ·æäº¤ï¼Œå¾—åˆ°æœ€ç»ˆæ­£ç¡®ç­”æ¡ˆã€‚

å½“ç„¶æˆ‘ä»¬åœ¨å¼€å‘ä¸­ä¹Ÿå¯ä»¥è¿™ä¹ˆå®ç°ï¼Œéšå¼åœ°å°†è¿™ä¸¤æ­¥å˜ä¸€æ­¥ï¼Œå¯ä»¥è·å¾—æ›´ç²¾å‡†çš„å›ç­”ã€‚



### ReAct

ReAatè¡¨ç¤ºçš„æ˜¯Reason+Actï¼Œé€šè¿‡è¿™ä¸ªä¾‹å­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºå‡ ç§æ¨¡å¼çš„åŒºåˆ«ã€‚

<figure><img src="../.gitbook/assets/image (3).png" alt=""><figcaption><p>Standard, Reason only, Act Only, ReActR</p></figcaption></figure>

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç”¨æˆ·æé—®çš„æ˜¯ï¼Œé™¤äº†Apple Remoteï¼Œè¿˜æœ‰åˆ«çš„ä»€ä¹ˆè®¾å¤‡å¯ä»¥æ§åˆ¶Apple Remoteç”¨æ¥äº¤äº’çš„é‚£ä¸ªç¨‹åºå—ï¼Ÿ

è¿™ä¸ªé—®é¢˜çœ‹ä¼¼ç®€å•ï¼Œå®é™…åŒ…å«äº† deviceå’Œprogramã€‚å¹¶ä¸”é’ˆå¯¹æ€§çš„é—®äº†å…³äºAppleæ–¹é¢çš„é—®é¢˜ã€‚

Reason onlyå…¶å®å°±æ˜¯ä¸Šé¢æåˆ°çš„CoTã€‚ä¸è¿‡è™½ç„¶å®ƒæœ‰ Step by Stepæ€ç»´ï¼Œç”±äºå®ƒæœ¬èº«çš„æ²¡æœ‰Appleç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯ï¼Œä¸”å¹¶æ²¡æœ‰é€šè¿‡å¤–éƒ¨æœç´¢ï¼Œä»…é€šè¿‡æ¨¡å‹è‡ªèº«çš„æ•°æ®æ¥å›ç­”ï¼Œæ˜¾ç„¶å›ç­”ä¸æ­£ç¡®ï¼Œè¿deviceå’Œprograméƒ½æ²¡æœ‰åŒºåˆ†å‡ºæ¥ã€‚

Act onlyç¡®å®æ˜¯é€šè¿‡å¤–éƒ¨èµ„æºæ¥æœç´¢äº†ï¼Œä½†å®ƒæ²¡æœ‰æ€ç»´é“¾ï¼Œå¯¼è‡´ç­”éæ‰€é—®ã€‚

ReActå°±å¾ˆå¥½çš„è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œå…ˆæ€è€ƒï¼Œå†Actè·å–å¤–éƒ¨ä¿¡æ¯æºObsï¼Œå¾€å¤å¾ªç¯ï¼Œæœ€ç»ˆå¾—åˆ°æ­£ç¡®çš„ç­”æ¡ˆï¼š\
_â€œKeyboard function keysâ€_

æ€»ç»“ä½œè€…çš„æ“ä½œæµç¨‹ï¼š

* round1: Thought, Act, Obs
* round2: Thought, Act, Obs
* round3: Thought, Act, Obs
* finally: Thought, Act



### What about AutoGPT?

è¿™é‡Œä»…é’ˆå¯¹æ—©æœŸçš„AutoGPTè¿›è¡Œç†è§£å’Œåˆ†æ

AutoGPTçœ‹ä¸Šå»ä¹Ÿæ˜¯é€šè¿‡step by stepæ¥å®Œæˆä»»åŠ¡ï¼Œä½†å®é™…æ˜¯å¦ç¬¦åˆCoTçš„ç†å¿µå‘¢ã€‚æ¨ä¸»Sverigeå¯¹AutoGPTçš„æºç è¿›è¡Œäº†è§£è¯»ã€‚

<figure><img src="../.gitbook/assets/image (11).png" alt=""><figcaption><p>AutoGPT</p></figcaption></figure>



AutoGPTä¸»è¦ç”±4éƒ¨åˆ†ç»„æˆï¼Œ User, Prompt postfix, Memory, Prompt Template

è¿™é‡ŒPrompt Templateæ˜¯å›ºå®šçš„ï¼Œè€Œtemplateçš„ç›®çš„æ˜¯ä¸ºäº†è§„èŒƒæ¨¡å‹å›ç­”ï¼Œè®©å…¶ç”Ÿæˆå¸¦æœ‰thoughtå’Œcommandçš„jsonï¼Œæ–¹ä¾¿commoandè¢«è§£æå‡ºæ¥æ“ä½œã€‚

è¿™é‡Œå…¶å®åˆ†ä¸ºäº†2ä¸ªé˜¶æ®µï¼Œåœ¨é˜¶æ®µä¸€ä¸­ï¼Œä¹Ÿå°±æ˜¯åˆå§‹æ—¶ï¼ŒMemoryçš„å†…å®¹æ˜¯ç©ºçš„ã€‚é€šè¿‡å’Œç”¨æˆ·çš„ç¬¬ä¸€æ¬¡äº¤äº’ï¼Œæ˜ç¡®ç¬¬ä¸€ä¸ªcommandï¼Œå¹¶ä¸”å°†è¿™äº›å†…å®¹å­˜å‚¨åœ¨Memoryä¸­ï¼›æ­¤æ—¶thoughtä¹ŸåŒæ—¶å’Œcommandä¸€èµ·å‡ºç°ã€‚AutoGPTä¸º Prompt postfixè®¾ç½®äº†ä¸€ä¸ªé»˜è®¤å€¼ï¼š\
_Determine which next command to use, and respond using the format specified above:_

ä»ç¬¬äºŒé˜¶æ®µå¼€å§‹ï¼Œåœ¨ç”¨æˆ·æ˜ç¡®é€‰æ‹©ä¹‹åï¼ŒPrompt postfixå˜æ›´ä¸ºï¼š\
_GENERATE NEXT COMMAND JSON_

ä»è¿™é‡Œå¼€å§‹ï¼Œä¹‹åçš„æ¯ä¸€æ­¥éƒ½æŒ‰ç…§é˜¶æ®µäºŒçš„ç¬¬ä¸€æ­¥å¼€å§‹å¾ªç¯æ‰§è¡Œã€‚

è¿™ä¸ªçœ‹ä¸Šå»æ˜¯æœ‰step by stepçš„æ€ç»´ï¼Œä½†CoTçš„æ¨¡å¼æ˜¯ï¼Œå°†CoTçš„å†…å®¹å¸¦ç»™ä¸‹ä¸€æ­¥promptã€‚è¿™é‡ŒAutoGPTæ‰§è¡Œçš„éƒ½æ˜¯ä¸Šä¸€æ­¥çš„commandï¼Œè€Œthoughtæ˜¯å’Œcommandä¸€èµ·è¢«ç”Ÿäº§çš„ï¼Œå¹¶æ²¡æœ‰è¢«å¸¦å…¥ä¸‹ä¸€æ­¥ä¸­ã€‚

æœ€ç»ˆä»è¿è¡Œæ•ˆæœæ¥çœ‹ï¼Œæ˜¯ç”Ÿæ•ˆçš„ã€‚ä½†å´è¢«è®¤ä¸ºä½æ•ˆ(ğŸ˜†)ï¼Œä¹Ÿå°±æ˜¯å¤§é‡æ¶ˆè€—äº†token(è´¹é’±)ã€‚



{% hint style="info" %}
Reference:

[GPT Best Practices - Strategy: Give GPTs time to "think"](https://platform.openai.com/docs/guides/gpt-best-practices/strategy-give-gpts-time-to-think)

[GPT Best Practices - Tactic: Use inner monologue or a sequence of queries to hide the model's reasoning process](https://platform.openai.com/docs/guides/gpt-best-practices/tactic-use-inner-monologue-or-a-sequence-of-queries-to-hide-the-model-s-reasoning-process)

[Azure - Chain of thought prompting](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#chain-of-thought-prompting)

[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)

[Sverige\_ Dong-seok](https://twitter.com/realrenmin) - [talk about CoT](https://twitter.com/realrenmin/status/1643241565031366657)

[Sverige\_Dong-seok - Does AutoGPT use CoT?](https://twitter.com/realrenmin/status/1647383612931870720)

[ReAct: Synergizing Reasoning and Acting in Language Models](https://react-lm.github.io/)
{% endhint %}

